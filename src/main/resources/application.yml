
spring:
    application:
        name: ollamaexperiment
    ai:
      ollama:
        base-url: http://localhost:11434
        chat:
          options:
            model: llava-llama3:latest
            temperature: 0.7